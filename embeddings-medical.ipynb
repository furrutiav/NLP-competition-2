{"cells":[{"cell_type":"code","source":["!pip3 install torchtext==0.9.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DTofoQY7dfGs","executionInfo":{"status":"ok","timestamp":1656200177491,"user_tz":240,"elapsed":99925,"user":{"displayName":"Benjamin Mellado","userId":"11384842880255366801"}},"outputId":"e290b2b5-b242-431b-c713-6f90491e9b07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchtext==0.9.0\n","  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 7.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (2.23.0)\n","Collecting torch==1.8.0\n","  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n","\u001b[K     |████████████████████████████████| 735.5 MB 14 kB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (4.64.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->torchtext==0.9.0) (4.1.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2.10)\n","Installing collected packages: torch, torchtext\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.11.0+cu113\n","    Uninstalling torch-1.11.0+cu113:\n","      Successfully uninstalled torch-1.11.0+cu113\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.12.0\n","    Uninstalling torchtext-0.12.0:\n","      Successfully uninstalled torchtext-0.12.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.8.0 which is incompatible.\n","torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.8.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.8.0 torchtext-0.9.0\n"]}]},{"cell_type":"code","source":["!pip install seqeval"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qILJb9arkgJI","executionInfo":{"status":"ok","timestamp":1656200187040,"user_tz":240,"elapsed":9554,"user":{"displayName":"Benjamin Mellado","userId":"11384842880255366801"}},"outputId":"1d0ff878-afd8-4d4d-9787-cc135ef5243c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 66 kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=c0f947ddc6836a824c144fc9d7786941e76b3e9f5fb7911e2955d3d43e638467\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n"]}]},{"cell_type":"code","source":["!wget https://zenodo.org/record/3924799/files/cwlce.vec -nc\n","!wget https://github.com/dccuchile/CC6205/releases/download/v1.0/train.txt -nc # Dataset de Entrenamiento\n","!wget https://github.com/dccuchile/CC6205/releases/download/v1.0/dev.txt -nc    # Dataset de Validación (Para probar y ajustar el modelo)\n","!wget https://github.com/dccuchile/CC6205/releases/download/v1.0/test.txt -nc  # Dataset de la Competencia. Estos datos solo contienen los tokens. ¡¡SON LOS QUE DEBEN SER PREDICHOS!!"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qy_7AMKFO3Z8","executionInfo":{"status":"ok","timestamp":1656200199375,"user_tz":240,"elapsed":12339,"user":{"displayName":"Benjamin Mellado","userId":"11384842880255366801"}},"outputId":"2c4b9e0b-bd03-46bb-ddc8-973e628c5b12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-06-25 23:36:30--  https://zenodo.org/record/3924799/files/cwlce.vec\n","Resolving zenodo.org (zenodo.org)... 137.138.76.77\n","Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 163303193 (156M) [application/octet-stream]\n","Saving to: ‘cwlce.vec’\n","\n","cwlce.vec           100%[===================>] 155.74M  19.3MB/s    in 9.2s    \n","\n","2022-06-25 23:36:40 (16.9 MB/s) - ‘cwlce.vec’ saved [163303193/163303193]\n","\n","--2022-06-25 23:36:41--  https://github.com/dccuchile/CC6205/releases/download/v1.0/train.txt\n","Resolving github.com (github.com)... 192.30.255.112\n","Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/196273020/77198f00-c145-11eb-83d1-11e647241ab6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220625%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220625T233641Z&X-Amz-Expires=300&X-Amz-Signature=58b7c2fe634d522de70c4860bb671c9f180cf5d9b10eb54031fd81de68b5f589&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196273020&response-content-disposition=attachment%3B%20filename%3Dtrain.txt&response-content-type=application%2Foctet-stream [following]\n","--2022-06-25 23:36:41--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/196273020/77198f00-c145-11eb-83d1-11e647241ab6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220625%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220625T233641Z&X-Amz-Expires=300&X-Amz-Signature=58b7c2fe634d522de70c4860bb671c9f180cf5d9b10eb54031fd81de68b5f589&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196273020&response-content-disposition=attachment%3B%20filename%3Dtrain.txt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1607913 (1.5M) [application/octet-stream]\n","Saving to: ‘train.txt’\n","\n","train.txt           100%[===================>]   1.53M  --.-KB/s    in 0.07s   \n","\n","2022-06-25 23:36:41 (21.5 MB/s) - ‘train.txt’ saved [1607913/1607913]\n","\n","--2022-06-25 23:36:41--  https://github.com/dccuchile/CC6205/releases/download/v1.0/dev.txt\n","Resolving github.com (github.com)... 192.30.255.112\n","Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/196273020/741e9e80-c145-11eb-813a-b9abac0d674c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220625%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220625T233641Z&X-Amz-Expires=300&X-Amz-Signature=a46bcd362f4dda7672b94519c91a9d79cbb67eefe87d985d6b58cf8bd306f603&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196273020&response-content-disposition=attachment%3B%20filename%3Ddev.txt&response-content-type=application%2Foctet-stream [following]\n","--2022-06-25 23:36:41--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/196273020/741e9e80-c145-11eb-813a-b9abac0d674c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220625%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220625T233641Z&X-Amz-Expires=300&X-Amz-Signature=a46bcd362f4dda7672b94519c91a9d79cbb67eefe87d985d6b58cf8bd306f603&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196273020&response-content-disposition=attachment%3B%20filename%3Ddev.txt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 177166 (173K) [application/octet-stream]\n","Saving to: ‘dev.txt’\n","\n","dev.txt             100%[===================>] 173.01K  --.-KB/s    in 0.01s   \n","\n","2022-06-25 23:36:42 (11.8 MB/s) - ‘dev.txt’ saved [177166/177166]\n","\n","--2022-06-25 23:36:42--  https://github.com/dccuchile/CC6205/releases/download/v1.0/test.txt\n","Resolving github.com (github.com)... 192.30.255.113\n","Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/196273020/75e86200-c145-11eb-94f8-49517311d768?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220625%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220625T233642Z&X-Amz-Expires=300&X-Amz-Signature=857024ae56e432595ff284857d252199b3658a702ee6769a9ceec453b7b8af8b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196273020&response-content-disposition=attachment%3B%20filename%3Dtest.txt&response-content-type=application%2Foctet-stream [following]\n","--2022-06-25 23:36:42--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/196273020/75e86200-c145-11eb-94f8-49517311d768?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220625%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220625T233642Z&X-Amz-Expires=300&X-Amz-Signature=857024ae56e432595ff284857d252199b3658a702ee6769a9ceec453b7b8af8b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196273020&response-content-disposition=attachment%3B%20filename%3Dtest.txt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 147052 (144K) [application/octet-stream]\n","Saving to: ‘test.txt’\n","\n","test.txt            100%[===================>] 143.61K  --.-KB/s    in 0.01s   \n","\n","2022-06-25 23:36:42 (10.2 MB/s) - ‘test.txt’ saved [147052/147052]\n","\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"wftkw0VmdYsF"},"outputs":[],"source":["import torch\n","from torchtext import data, datasets, legacy\n","import numpy as np\n","import pandas as pd\n","from collections import Counter\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"id":"VuJIko2MdYsG"},"outputs":[],"source":["MEDICAL_VECTORS_FILE = 'cwlce.vec'"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"id":"3OKtCqs6dYsH"},"outputs":[],"source":["def load_medical_vectors(vectors_file=MEDICAL_VECTORS_FILE):\n","    \"\"\"Load the glove word vectors\"\"\"\n","    word_vectors = {}\n","    with open(vectors_file) as f:\n","        first = True\n","        for line in f:\n","            if first:\n","                first = False\n","                continue\n","            split = line.split()\n","            word_vectors[split[0]] = np.array([float(x) for x in split[1:]])\n","    return word_vectors"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"id":"5a9mdLlgdYsI"},"outputs":[],"source":["def get_emb_matrix(word_vecs, word_counts, emb_size=300, random_UNK = False, UNK_IDX=0):\n","    \"\"\" Creates embedding matrix from word vectors\"\"\"\n","    vocab_size = len(word_counts)\n","    vocab_to_idx = {}\n","    vocab = []\n","    W = np.zeros((vocab_size, emb_size), dtype=\"float32\")\n","    i = 2\n","    UNK_VOCAB_INDEX = 0\n","    \n","    vocab_to_idx[\"<unk>\"] = 0\n","    vocab.append(\"<unk>\")\n","    W[0] = np.random.uniform(-0.25, 0.25, emb_size)  # adding a vector for unknown words\n","    vocab_to_idx[\"<pad>\"] = 1\n","    vocab.append(\"<pad>\")\n","    W[1] = np.random.uniform(-0.25, 0.25, emb_size)  # adding a vector for unknown words\n","    \n","    \n","    for word in word_counts[2:]:\n","        if word in word_vecs:\n","            W[i] = word_vecs[word]\n","            vocab_to_idx[word] = i\n","            vocab.append(word)\n","        else:\n","            if random_UNK:\n","              W[i] = np.random.uniform(-0.25, 0.25, emb_size)\n","              vocab_to_idx[word] = i\n","              vocab.append(word)\n","            else:\n","              W[i] = np.zeros(emb_size, dtype='float32')  # adding a vector for padding\n","              vocab_to_idx[word] = 0\n","              vocab.append(word)  \n","            \n","        i += 1\n","        \n","    return W, np.array(vocab), vocab_to_idx"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"id":"7L3B0OZadYsI"},"outputs":[],"source":["# Primer Field: TEXT. Representan los tokens de la secuencia\n","TEXT = legacy.data.Field(lower=True)\n","\n","# Segundo Field: NER_TAGS. Representan los Tags asociados a cada palabra.\n","NER_TAGS = legacy.data.Field(unk_token=None)\n","fields = ((\"text\", TEXT), (\"nertags\", NER_TAGS))"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"id":"WTZyO-64dYsJ"},"outputs":[],"source":["train_data, valid_data, test_data = legacy.datasets.SequenceTaggingDataset.splits(\n","    path=\"./\",\n","    train=\"train.txt\",\n","    validation=\"dev.txt\",\n","    test=\"test.txt\",\n","    fields=fields,\n","    encoding=\"utf-8\",\n","    separator=\" \"\n",")"]},{"cell_type":"code","source":["TEXT.build_vocab(train_data)\n","NER_TAGS.build_vocab(train_data)"],"metadata":{"id":"cFhmLeey3V9D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Tokens únicos en TEXT: {len(TEXT.vocab)}\")\n","print(f\"Tokens únicos en NER_TAGS: {len(NER_TAGS.vocab)}\")\n","print(NER_TAGS.vocab.itos)\n","print(TEXT.vocab.itos[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y707rGDL3W-e","executionInfo":{"status":"ok","timestamp":1656200201037,"user_tz":240,"elapsed":7,"user":{"displayName":"Benjamin Mellado","userId":"11384842880255366801"}},"outputId":"58fcdb7b-0a49-424e-dc9c-ba2c0893ab04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokens únicos en TEXT: 12772\n","Tokens únicos en NER_TAGS: 12\n","['<pad>', 'O', 'I-Disease', 'B-Disease', 'I-Body_Part', 'B-Body_Part', 'B-Procedure', 'I-Procedure', 'B-Medication', 'B-Family_Member', 'I-Medication', 'I-Family_Member']\n","['<unk>', '<pad>', 'de', '.', ',', '-', 'con', 'y', 'en', '/']\n"]}]},{"cell_type":"code","source":["UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","PAD_TAG_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n","O_TAG_IDX = NER_TAGS.vocab.stoi['O']"],"metadata":{"id":"qTvBTMO08CnU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TEXT.vocab.itos[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LAYC2kx08C9c","executionInfo":{"status":"ok","timestamp":1656200201037,"user_tz":240,"elapsed":5,"user":{"displayName":"Benjamin Mellado","userId":"11384842880255366801"}},"outputId":"45c4a99b-24fa-47c0-a89a-778c2dc75372"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<unk>', '<pad>', 'de', '.', ',', '-', 'con', 'y', 'en', '/']"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["word_vecs = load_medical_vectors()"],"metadata":{"id":"D1oaiYxG8Da_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pretrained_weights, words, vocab2index = get_emb_matrix(word_vecs, TEXT.vocab.itos, 300,  True)"],"metadata":{"id":"RR18DcHI8D39"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pretrained_weights.shape, len(TEXT.vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tb5yfHFkByUF","executionInfo":{"status":"ok","timestamp":1656200209789,"user_tz":240,"elapsed":366,"user":{"displayName":"Benjamin Mellado","userId":"11384842880255366801"}},"outputId":"b39ffe10-1b38-4f8b-fd99-bca3a2085811"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((12772, 300), 12772)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["words[:10], TEXT.vocab.itos[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z9nN32g6ByKR","executionInfo":{"status":"ok","timestamp":1656200209789,"user_tz":240,"elapsed":6,"user":{"displayName":"Benjamin Mellado","userId":"11384842880255366801"}},"outputId":"0e8e0e6f-0d7d-4271-ce97-9c213537ff16"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array(['<unk>', '<pad>', 'de', '.', ',', '-', 'con', 'y', 'en', '/'],\n","       dtype='<U28'),\n"," ['<unk>', '<pad>', 'de', '.', ',', '-', 'con', 'y', 'en', '/'])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":[""],"metadata":{"id":"HnfOivWHBxxM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fhlRP5btdYsO"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NILSSd3sdYsO"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"6hTOsFA3dYsO"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"id":"p0wxzdO_dYsO"},"source":["#### **Métricas de evaluación**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ynxRtyAdYsP"},"outputs":[],"source":["# Definimos las métricas\n","\n","from seqeval.metrics import f1_score, precision_score, recall_score\n","\n","def calculate_metrics(preds, y_true, pad_idx=PAD_TAG_IDX, o_idx=O_TAG_IDX):\n","    \"\"\"\n","    Calcula precision, recall y f1 de cada batch.\n","    \"\"\"\n","\n","    # Obtener el indice de la clase con probabilidad mayor. (clases)\n","    y_pred = preds.argmax(dim=1, keepdim=True)\n","\n","    # filtramos <pad> para calcular los scores.\n","    mask = [(y_true != pad_idx)]\n","    y_pred = y_pred[mask]\n","    y_true = y_true[mask]\n","\n","    # traemos a la cpu\n","    y_pred = y_pred.view(-1).to('cpu').numpy()\n","    y_true = y_true.to('cpu').numpy()\n","    y_pred = [[NER_TAGS.vocab.itos[v] for v in y_pred]]\n","    y_true = [[NER_TAGS.vocab.itos[v] for v in y_true]]\n","    \n","    # calcular scores\n","    f1 = f1_score(y_true, y_pred, mode='strict')\n","    precision = precision_score(y_true, y_pred, mode='strict')\n","    recall = recall_score(y_true, y_pred, mode='strict')\n","\n","    return precision, recall, f1"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"id":"GptTMEQIdYsP"},"outputs":[],"source":["# Garantizar reproducibilidad de los experimentos\n","SEED = 1234\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"id":"YTrDR6oKdYsP","outputId":"6976d5a3-4635-41f4-db9c-f7075227bc10","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656200210348,"user_tz":240,"elapsed":5,"user":{"displayName":"Benjamin Mellado","userId":"11384842880255366801"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda\n"]}],"source":["BATCH_SIZE = 64  # disminuir si hay problemas de ram.\n","\n","# Usar cuda si es que está disponible.\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using', device)\n","\n","# Dividir datos entre entrenamiento y test. Si van a hacer algún sort no puede ser sobre\n","# el conjunto de testing ya que al hacer sus predicciones sobre el conjunto de test sin etiquetas\n","# debe conservar el orden original para ser comparado con los golden_labels.\n","\n","train_iterator, valid_iterator, test_iterator = legacy.data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size=BATCH_SIZE,\n","    device=device,\n","    sort=False,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oaq9-5FkdYsQ"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","\n","# Definir la red\n","class NER_RNN(nn.Module):\n","    def __init__(self, \n","                 input_dim, \n","                 embedding_dim, \n","                 hidden_dim, \n","                 output_dim,\n","                 n_layers, \n","                 bidirectional, \n","                 dropout, \n","                 pad_idx,\n","                 load_embeddings=False,\n","                 embeddings=None):\n","\n","        super().__init__()\n","\n","        # Capa de embedding\n","        self.embedding = nn.Embedding(input_dim,\n","                                      embedding_dim,\n","                                      padding_idx=pad_idx)\n","        if (load_embeddings):\n","            self.embedding.weight.data.copy_(embeddings)\n","        self.embedding.weight.requires_grad = not load_embeddings ## freeze embeddings\n","\n","        # Capa LSTM\n","        self.lstm = nn.LSTM(embedding_dim,\n","                           hidden_dim,\n","                           num_layers=n_layers,\n","                           bidirectional=bidirectional, \n","                           dropout = dropout if n_layers > 1 else 0)\n","\n","        # Capa de salida\n","        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n","                            output_dim)\n","\n","        # Dropout\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, text):\n","\n","        #text = [sent len, batch size]\n","\n","        # Convertir lo enviado a embedding\n","        embedded = self.dropout(self.embedding(text))\n","        \n","        outputs, (hidden, cell) = self.lstm(embedded)\n","        #embedded = [sent len, batch size, emb dim]\n","\n","        # Pasar los embeddings por la rnn (LSTM)\n","\n","        #output = [sent len, batch size, hid dim * n directions]\n","        #hidden/cell = [n layers * n directions, batch size, hid dim]\n","\n","        # Predecir usando la capa de salida.\n","        predictions = self.fc(self.dropout(outputs))\n","        #predictions = [sent len, batch size, output dim]\n","\n","        return predictions"]},{"cell_type":"code","source":["class CNN_NLP(nn.Module):\n","    \"\"\"An 1D Convulational Neural Network for Sentence Classification.\"\"\"\n","    def __init__(self,\n","                 pretrained_embedding=None,\n","                 freeze_embedding=False,\n","                 vocab_size=None,\n","                 embed_dim=300,\n","                 filter_sizes=[3, 4, 5],\n","                 num_filters=[100, 100, 100],\n","                 num_classes=2,\n","                 dropout=0.5,\n","                 pad_idx=1):\n","        \"\"\"\n","        The constructor for CNN_NLP class.\n","\n","        Args:\n","            pretrained_embedding (torch.Tensor): Pretrained embeddings with\n","                shape (vocab_size, embed_dim)\n","            freeze_embedding (bool): Set to False to fine-tune pretraiend\n","                vectors. Default: False\n","            vocab_size (int): Need to be specified when not pretrained word\n","                embeddings are not used.\n","            embed_dim (int): Dimension of word vectors. Need to be specified\n","                when pretrained word embeddings are not used. Default: 300\n","            filter_sizes (List[int]): List of filter sizes. Default: [3, 4, 5]\n","            num_filters (List[int]): List of number of filters, has the same\n","                length as `filter_sizes`. Default: [100, 100, 100]\n","            n_classes (int): Number of classes. Default: 2\n","            dropout (float): Dropout rate. Default: 0.5\n","        \"\"\"\n","\n","        super(CNN_NLP, self).__init__()\n","        # Embedding layer\n","        if pretrained_embedding is not None:\n","            self.vocab_size, self.embed_dim = pretrained_embedding.shape\n","            self.embedding = nn.Embedding.from_pretrained(pretrained_embedding,\n","                                                          freeze=freeze_embedding,\n","                                                          padding_idx=pad_idx)\n","        else:\n","            self.embed_dim = embed_dim\n","            self.embedding = nn.Embedding(num_embeddings=vocab_size,\n","                                          embedding_dim=self.embed_dim,\n","                                          padding_idx=0,\n","                                          max_norm=5.0)\n","        # Conv Network\n","        self.conv1d_list = nn.ModuleList([\n","            nn.Conv1d(in_channels=self.embed_dim,\n","                      out_channels=num_filters[i],\n","                      kernel_size=filter_sizes[i])\n","            for i in range(len(filter_sizes))\n","        ])\n","        # Fully-connected layer and Dropout\n","        self.fc = nn.Linear(np.sum(num_filters), num_classes)\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, input_ids):\n","        \"\"\"Perform a forward pass through the network.\n","\n","        Args:\n","            input_ids (torch.Tensor): A tensor of token ids with shape\n","                (batch_size, max_sent_length)\n","\n","        Returns:\n","            logits (torch.Tensor): Output logits with shape (batch_size,\n","                n_classes)\n","        \"\"\"\n","\n","        # Get embeddings from `input_ids`. Output shape: (b, max_len, embed_dim)\n","        x_embed = self.embedding(input_ids).float()\n","\n","\n","        # Permute `x_embed` to match input shape requirement of `nn.Conv1d`.\n","        # Output shape: (b, embed_dim, max_len)\n","        x_reshaped = x_embed.permute(0, 2, 1)\n","\n","        # Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\n","        x_conv_list = [F.relu(conv1d(x_reshaped)) for conv1d in self.conv1d_list]\n","\n","        # Max pooling. Output shape: (b, num_filters[i], 1)\n","        x_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2])\n","            for x_conv in x_conv_list]\n","        \n","        # Concatenate x_pool_list to feed the fully connected layer.\n","        # Output shape: (b, sum(num_filters))\n","        x_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in x_pool_list],\n","                         dim=1)\n","        \n","        # Compute logits. Output shape: (b, n_classes)\n","        logits = self.fc(self.dropout(x_fc))\n","\n","        return logits"],"metadata":{"id":"hJl5aeTRqQgU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(TEXT.vocab),  pretrained_weights.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hVHbA180DzhC","executionInfo":{"status":"ok","timestamp":1656200210743,"user_tz":240,"elapsed":398,"user":{"displayName":"Benjamin Mellado","userId":"11384842880255366801"}},"outputId":"dd804d71-cf55-40a8-81fc-8ab7faf77119"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12772, (12772, 300))"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PTGrBNv7dYsQ"},"outputs":[],"source":["# tamaño del vocabulario. recuerden que la entrada son vectores bag of word(one-hot).\n","INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 300  # dimensión de los embeddings.\n","HIDDEN_DIM = 256  # dimensión de la capas LSTM\n","OUTPUT_DIM = len(NER_TAGS.vocab)  # número de clases\n","\n","N_LAYERS = 3  # número de capas.\n","DROPOUT = 0.2\n","BIDIRECTIONAL = True\n","pretrained_weights = torch.tensor(pretrained_weights).to(device)\n","\n","# Creamos nuestro modelo.\n","baseline_model = NER_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n","                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX, True, pretrained_weights)\n","\n","# baseline_model = CNN_NLP(pretrained_weights, True, INPUT_DIM, 300, filter_sizes=[3, 4, 5],\n","#                  num_filters=[100, 100, 100],\n","#                  num_classes=OUTPUT_DIM)\n","\n","baseline_model_name = 'baseline'  # nombre que tendrá el modelo guardado..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dr6pJIrodYsR"},"outputs":[],"source":["baseline_criterion = nn.CrossEntropyLoss(ignore_index = 0)\n","baseline_n_epochs = 150"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u_rzRegTdYsR"},"outputs":[],"source":["model = baseline_model\n","model_name = baseline_model_name\n","criterion = baseline_criterion\n","n_epochs = baseline_n_epochs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_noIaIDzdYsR","outputId":"2fb4d21a-9136-4fe3-dbb9-d6196b1d6f56","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656200214507,"user_tz":240,"elapsed":54,"user":{"displayName":"Benjamin Mellado","userId":"11384842880255366801"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["NER_RNN(\n","  (embedding): Embedding(12772, 300, padding_idx=1)\n","  (lstm): LSTM(300, 256, num_layers=3, dropout=0.2, bidirectional=True)\n","  (fc): Linear(in_features=512, out_features=12, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n",")"]},"metadata":{},"execution_count":27}],"source":["def init_weights(m):\n","    # Inicializamos los pesos como aleatorios\n","    for name, param in m.named_parameters():\n","        nn.init.normal_(param.data, mean=0, std=0.1) \n","        \n","    # Seteamos como 0 los embeddings de UNK y PAD.\n","    # model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n","    # model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","        \n","model.apply(init_weights)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IFI-J4LEdYsR","outputId":"097b50a4-c478-45da-ca6c-5f4857229fd2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656200214508,"user_tz":240,"elapsed":54,"user":{"displayName":"Benjamin Mellado","userId":"11384842880255366801"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["El modelo actual tiene 4,302,860 parámetros entrenables.\n"]}],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(f'El modelo actual tiene {count_parameters(model):,} parámetros entrenables.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"93sSXyZxdYsS"},"outputs":[],"source":["# Optimizador\n","optimizer = optim.Adam(model.parameters())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zuPe2OAidYsS","executionInfo":{"status":"error","timestamp":1656200214777,"user_tz":240,"elapsed":321,"user":{"displayName":"Benjamin Mellado","userId":"11384842880255366801"}},"colab":{"base_uri":"https://localhost:8080/","height":345},"outputId":"8f0fe7d3-fb61-41af-dd9f-f1b8e656e4b6"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-e7884581cd60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Enviamos el modelo y la loss a cuda (en el caso en que esté disponible)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# Flattens params (on CUDA)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mflatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cudnn_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                         self.batch_first, bool(self.bidirectional))  # type: ignore\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED"]}],"source":["# Enviamos el modelo y la loss a cuda (en el caso en que esté disponible)\n","model = model.to(device)\n","criterion = criterion.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zgTmx3t3dYsS"},"outputs":[],"source":["def train(model, iterator, optimizer, criterion):\n","\n","    epoch_loss = 0\n","    epoch_precision = 0\n","    epoch_recall = 0\n","    epoch_f1 = 0\n","\n","    model.train()\n","\n","    # Por cada batch del iterador de la época:\n","    for batch in iterator:\n","\n","        # Extraemos el texto y los tags del batch que estamos procesado\n","        text = batch.text\n","        tags = batch.nertags\n","\n","        # Reiniciamos los gradientes calculados en la iteración anterior\n","        optimizer.zero_grad()\n","\n","        #text = [sent len, batch size]\n","\n","        # Predecimos los tags del texto del batch.\n","        predictions = model(text)\n","\n","        #predictions = [sent len, batch size, output dim]\n","        #tags = [sent len, batch size]\n","\n","        # Reordenamos los datos para calcular la loss\n","        predictions = predictions.view(-1, predictions.shape[-1])\n","        tags = tags.view(-1)\n","\n","        #predictions = [sent len * batch size, output dim]\n","\n","\n","\n","        # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n","        loss = criterion(predictions, tags)\n","        \n","        # Calculamos el accuracy\n","        precision, recall, f1 = calculate_metrics(predictions, tags)\n","\n","        # Calculamos los gradientes\n","        loss.backward()\n","\n","        # Actualizamos los parámetros de la red\n","        optimizer.step()\n","\n","        # Actualizamos el loss y las métricas\n","        epoch_loss += loss.item()\n","        epoch_precision += precision\n","        epoch_recall += recall\n","        epoch_f1 += f1\n","\n","    return epoch_loss / len(iterator), epoch_precision / len(\n","        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x6bP-qeYdYsS"},"outputs":[],"source":["def evaluate(model, iterator, criterion):\n","\n","    epoch_loss = 0\n","    epoch_precision = 0\n","    epoch_recall = 0\n","    epoch_f1 = 0\n","\n","    model.eval()\n","\n","    # Indicamos que ahora no guardaremos los gradientes\n","    with torch.no_grad():\n","        # Por cada batch\n","        for batch in iterator:\n","\n","            text = batch.text\n","            tags = batch.nertags\n","\n","            # Predecimos\n","            predictions = model(text)\n","\n","            predictions = predictions.view(-1, predictions.shape[-1])\n","            tags = tags.view(-1)\n","\n","            # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n","            loss = criterion(predictions, tags)\n","\n","            # Calculamos las métricas\n","            precision, recall, f1 = calculate_metrics(predictions, tags)\n","\n","            # Actualizamos el loss y las métricas\n","            epoch_loss += loss.item()\n","            epoch_precision += precision\n","            epoch_recall += recall\n","            epoch_f1 += f1\n","\n","    return epoch_loss / len(iterator), epoch_precision / len(\n","        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bZ9_ZGBpdYsS"},"outputs":[],"source":["import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DpzEyF9CdYsT"},"outputs":[],"source":["best_valid_loss = float('inf')\n","\n","for epoch in range(n_epochs):\n","\n","    start_time = time.time()\n","\n","    # Recuerdo: train_iterator y valid_iterator contienen el dataset dividido en batches.\n","\n","    # Entrenar\n","    train_loss, train_precision, train_recall, train_f1 = train(\n","        model, train_iterator, optimizer, criterion)\n","\n","    # Evaluar (valid = validación)\n","    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n","        model, valid_iterator, criterion)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    # Si obtuvimos mejores resultados, guardamos este modelo en el almacenamiento (para poder cargarlo luego)\n","    # Si detienen el entrenamiento prematuramente, pueden cargar el modelo en el siguiente recuadro de código.\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), '{}.pt'.format(model_name))\n","    # Si ya no mejoramos el loss de validación, terminamos de entrenar.\n","\n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(\n","        f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n","    )\n","    print(\n","        f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n","    )"]},{"cell_type":"code","source":["model.load_state_dict(torch.load('{}.pt'.format(model_name)))"],"metadata":{"id":"6VjX7nN1SpyI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"GRIXA4FRSqnV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n","    model, valid_iterator, criterion)\n","\n","print(\n","    f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",")"],"metadata":{"id":"2vc1qDH2SzAl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4_khm21qdYsU"},"outputs":[],"source":["def predict_labels(model, iterator, criterion, fields=fields):\n","\n","    # Extraemos los vocabularios.\n","    text_field = fields[0][1]\n","    nertags_field = fields[1][1]\n","    tags_vocab = nertags_field.vocab.itos\n","    words_vocab = text_field.vocab.itos\n","\n","    model.eval()\n","\n","    predictions = []\n","\n","    with torch.no_grad():\n","\n","        for batch in iterator:\n","\n","            text_batch = batch.text\n","            text_batch = torch.transpose(text_batch, 0, 1).tolist()\n","\n","            # Predecir los tags de las sentences del batch\n","            predictions_batch = model(batch.text)\n","            predictions_batch = torch.transpose(predictions_batch, 0, 1)\n","\n","            # por cada oración predicha:\n","            for sentence, sentence_prediction in zip(text_batch,\n","                                                     predictions_batch):\n","                for word_idx, word_predictions in zip(sentence,\n","                                                      sentence_prediction):\n","                    # Obtener el indice del tag con la probabilidad mas alta.\n","                    argmax_index = word_predictions.topk(1)[1]\n","\n","                    current_tag = tags_vocab[argmax_index]\n","                    # Obtenemos la palabra\n","                    current_word = words_vocab[word_idx]\n","\n","                    if current_word != '<pad>':\n","                        predictions.append([current_word, current_tag])\n","                predictions.append(['EOS', 'EOS'])\n","\n","\n","    return predictions\n","\n","\n","predictions = predict_labels(model, test_iterator, criterion)"]},{"cell_type":"code","source":["import os, shutil\n","\n","if (os.path.isfile('./predictions.zip')):\n","    os.remove('./predictions.zip')\n","\n","if (not os.path.isdir('./predictions')):\n","    os.mkdir('./predictions')\n","\n","else:\n","    # Eliminar predicciones anteriores:\n","    shutil.rmtree('./predictions')\n","    os.mkdir('./predictions')\n","\n","f = open('predictions/predictions.txt', 'w')\n","for i, (word, tag) in enumerate(predictions[:-1]):\n","    if word=='EOS' and tag=='EOS': f.write('\\n')\n","    else: \n","      if i == len(predictions[:-1])-1:\n","        f.write(word + ' ' + tag)\n","      else: f.write(word + ' ' + tag + '\\n')\n","\n","f.close()\n","\n","a = shutil.make_archive('predictions', 'zip', './predictions')"],"metadata":{"id":"vt1VVCd2PDLs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"O0Ks8xYnUwQ0"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"colab":{"name":"embeddings-medical.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}