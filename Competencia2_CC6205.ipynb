{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0tyIsliieNr"
   },
   "source": [
    "# **Competencia 2 - CC6205 Natural Language Processing üìö**\n",
    "\n",
    "Integrantes:\n",
    "\n",
    "Usuario del equipo en CodaLab (Obligatorio):\n",
    "\n",
    "Fecha l√≠mite de entrega üìÜ: 16 de Junio.\n",
    "\n",
    "Tiempo estimado de dedicaci√≥n:\n",
    "\n",
    "Link competencia: Poner el link aqu√≠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MocJN22HSJ1x"
   },
   "source": [
    "### **Objetivo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwdgXS8FSLvc"
   },
   "source": [
    "El objetivo de esta competencia es resolver una de las tareas m√°s importantes en el √°rea del procesamiento de lenguage natural, relacionada con la extracci√≥n de informaci√≥n: [Named Entity Recognition (NER)](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf). \n",
    "\n",
    "En particular, y al igual que en la competencia anterior, deber√°n crear distintos modelos que apunten a resolver la tarea de NER en Espa√±ol. Para esto, les entregaremos un dataset real perteneciente a la lista de espera NO GES en Chile. Es importante destacar que existe una falta de trabajos realizados en el √°rea de NER en Espa√±ol y a√∫n m√°s en el contexto cl√≠nico, por ende puede ser considerado como una tarea bien desafiante y quiz√°s les interesa trabajar en el √°rea m√°s adelante en sus carreras.\n",
    "\n",
    "En este notebook les entregaremos un baseline como referencia de los resultados que esperamos puedan obtener. Recuerden que el no superar a los baselines en alguna de las tres m√©tricas conlleva un descuento de 0.5 puntos hasta 1.5 puntos.\n",
    "\n",
    "Como hemos estado viendo redes neuronales tanto en catedras, tareas y auxiliares (o pr√≥ximamente lo har√°n), esperamos que (por lo menos) utilicen Redes Neuronales Recurrentes (RNN) para resolverla. \n",
    "\n",
    "Nuevamente, hay total libertad para utilizar el software y los modelos que deseen, siempre y cuando estos no traigan los modelos ya implementados. (De todas maneras como es un corpus nuevo, es dif√≠cil que haya alg√∫n modelo ya implementado con estas entidades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnjgmvjBSReb"
   },
   "source": [
    "### **Explicaci√≥n de la competencia**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NH4HqnCjSWs-"
   },
   "source": [
    "La tarea **NER** que van a resolver en esta competencia es com√∫nmente abordada como un problema de Sequence Labeling.\n",
    "\n",
    "**¬øQu√© es Sequence Labeling?** \n",
    "\n",
    "En breves palabras, dada una secuencia de tokens (oraci√≥n) sequence labeling tiene por objetivo asignar una etiqueta a cada token de dicha secuencia. En pocas palabras, dada una lista de tokens esperamos encontrar la mejor secuencia de etiquetas asociadas a esa lista. Ahora veamos de qu√© se trata este problema.\n",
    "\n",
    "**Named Entity Recognition (NER)**\n",
    "\n",
    "NER es un ejemplo de un problema de Sequence Labeling. Pero antes de definir formalmente esta tarea, es necesario definir algunos conceptos claves para poder entenderla de la mejor manera:\n",
    "\n",
    "- *Token*: Un token es una secuencia de caracteres, puede ser una palabra, un n√∫mero o un s√≠mbolo.\n",
    "\n",
    "- *Entidad*: No es m√°s que un trozo de texto (uno o m√°s tokens) asociado a una categor√≠a predefinida. Originalmente se sol√≠an utilizar categor√≠as como nombres de personas, organizaciones, ubicaciones, pero actualmente se ha extendido a diferentes dominios.\n",
    "\n",
    "- *L√≠mites de una entidad*: Son los √≠ndices de los tokens de inicio y f√≠n dentro de una entidad.\n",
    "\n",
    "- *Tipo de entidad*: Es la categor√≠a predefinida asociada a la entidad.\n",
    "\n",
    "Dicho esto, definimos formalmente una entidad como una tupla: $(s, e, t)$, donde $s, t$ son los l√≠mites de la entidad (√≠ndices de los tokens de inicio y fin, respectivamente) y t corresponde al tipo de entidad o categor√≠a. Ya veremos m√°s ejemplos luego de describir el Dataset.\n",
    "\n",
    "**Corpus de la Lista de espera**\n",
    "\n",
    "Trabajaran con un conjunto de datos reales correspondiente a interconsultas de la lista de espera NO GES en Chile. Si quieren saber m√°s sobre c√≥mo fueron generados los datos pueden revisar el paper publicado hace unos meses atr√°s en el workshop de EMNLP, una de las conferencias m√°s importantes de NLP: [https://www.aclweb.org/anthology/2020.clinicalnlp-1.32/](https://www.aclweb.org/anthology/2020.clinicalnlp-1.32/).\n",
    "\n",
    "Este corpus Chileno est√° constituido originalmente por 7 tipos de entidades pero por simplicidad en esta competencia trabajar√°n con las siguientes:\n",
    "\n",
    "- **Disease**\n",
    "- **Body_Part**\n",
    "- **Medication** \n",
    "- **Procedures** \n",
    "- **Family_Member**\n",
    "\n",
    "Si quieren obtener m√°s informaci√≥n sobre estas entidades pueden consultar la [gu√≠a de anotaci√≥n](https://plncmm.github.io/annodoc/). Adem√°s, mencionar que este corpus est√° restringido bajo una licencia que permite solamente su uso acad√©mico, as√≠ que no puede ser compartido m√°s all√° de este curso o sin permisos por parte de los autores en caso que quieran utilizarlo fuera. Si este √∫ltimo es el caso entonces pueden escribir directamente al correo: pln@cmm.uchile.cl. Al aceptar los t√©rminos y condiciones de la competencia est√°n de acuerdo con los puntos descritos anteriormente.\n",
    "\n",
    "\n",
    "**Formato ConLL**\n",
    "\n",
    "Los archivos que ser√°n entregados a ustedes vienen en un formato est√°ndar utilizado en NER, llamado ConLL. No es m√°s que un archivo de texto, que cumple las siguientes propiedades.\n",
    "\n",
    "- Un salto de linea corresponde a la separaci√≥n entre oraciones. Esto es importante ya que al entrenar una red neuronal ustedes pasaran una lista de oraciones como input, m√°s conocidos como batches.\n",
    "\n",
    "- La primera columna del archivo contiene todos los tokens de la partici√≥n.\n",
    "\n",
    "- La segunda columna del archivo contiene el tipo de entidad asociado al token de la primera columna.\n",
    "\n",
    "- Los tipos de entidades siguen un formato cl√°sico en NER denominado *IOB2*. Si un tipo de entidad comienza con el prefijo \"B-\" (Beginning) significa que es el token de inicio de una entidad, si comienza con \"I-\" (Inside) es un token distinto al de inicio y si un token est√° asociado a la categor√≠a O (Outside) significa que no pertenece a ninguna entidad.\n",
    "\n",
    "Aqu√≠ va un ejemplo:\n",
    "\n",
    "```\n",
    "PACIENTE O\n",
    "PRESENTA O\n",
    "FRACTURA B-Disease\n",
    "CORONARIA I-Disease\n",
    "COMPLICADA I-Disease\n",
    "EN O\n",
    "PIE B-Body_Part\n",
    "IZQUIERDO I-Body_Part\n",
    ". O\n",
    "SE O\n",
    "REALIZA O\n",
    "INSTRUMENTACION B-Procedure\n",
    "INTRACONDUCTO I-Procedure\n",
    ". O\n",
    "```\n",
    "\n",
    "Seg√∫n nuestra definici√≥n tenemos las siguientes tres entidades (enumerando desde 0): \n",
    "\n",
    "- $(2, 4, Disease)$\n",
    "- $(6, 7, Body Part)$\n",
    "- $(11, 12, Procedure)$\n",
    "\n",
    "Repasen un par de veces todos estos conceptos antes de pasar a la siguiente secci√≥n del notebook.\n",
    "Es importante entender bien este formato ya que al medir el rendimiento de sus modelos, consideraremos una **m√©trica estricta**. Esta m√©trica se llama as√≠ ya que considera correcta una predicci√≥n de su modelo, s√≥lo si al compararlo con las entidades reales **coinciden tanto los l√≠mites de la entidad como el tipo.** \n",
    "\n",
    "Para ejemplificar, tomando el caso anterior, si el modelo es capaz de encontrar la siguiente entidad: $(2, 3, Disease)$, entonces se considera incorrecto ya que pudo predecir dos de los tres tokens de dicha enfermedad. Es decir, buscamos una m√©trica que sea alta a nivel de entidad y no a nivel de token.\n",
    "\n",
    "Antes de pasar a explicar las reglas, se recomienda visitar los siguientes links para entender bien el baseline de la competencia:\n",
    "\n",
    "-  [Tagging, and Hidden Markov Models ](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf) (slides by Michael Collins), [notes](http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf), [video 1](https://youtu.be/-ngfOZz8yK0), [video 2](https://youtu.be/PLoLKQwkONw), [video 3](https://youtu.be/aaa5Qoi8Vco), [video 4](https://youtu.be/4pKWIDkF_6Y)       \n",
    "-  [Recurrent Neural Networks](slides/NLP-RNN.pdf) | [video 1](https://youtu.be/BmhjUkzz3nk), [video 2](https://youtu.be/z43YFR1iIvk), [video 3](https://youtu.be/7L5JxQdwNJk)\n",
    "\n",
    "\n",
    "Recuerden que todo el material se encuentra disponible en el [github del curso](https://github.com/dccuchile/CC6205)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWlfabmkaSE7"
   },
   "source": [
    "### **Reglas de la competencia**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3w9Dw4CSaSE8"
   },
   "source": [
    "- Para que su competencia sea evaluada, deben participar en la competencia y enviar este notebook con su informe.\n",
    "- Para participar, deben registrarse en la competencia en Codalab en grupos de m√°ximo 3 alumnos. Cada grupo debe tener un nombre de equipo. (¬°Y deben reportarlo en su informe, por favor!)\n",
    "- Las m√©tricas usadas ser√°n m√©tricas estrictas (ya explicado anteriormente) utilizando m√©tricas cl√°sicas como lo son precisi√≥n, recall y micro f1-score.\n",
    "- En esta tarea se recomienda usar GPU. Pueden ejecutar su tarea en colab (lo cual trae todo instalado) o pueden intentar ejecut√°ndolo en su computador. En este caso, deber√° ser compatible con cuda y deber√°n instalar todo por su cuenta.\n",
    "- En total pueden hacer un **m√°ximo de 5 env√≠os**.\n",
    "- Por favor, todas sus dudas haganlas por el canal de Discord. Los emails que lleguen al equipo docente ser√°n remitidos a ese medio. Recuerden el √°nimo colaborativo del curso.\n",
    "- Estar top 5 en alguna de las tres m√©tricas equivale a una bonificaci√≥n en su nota final.\n",
    "\n",
    "√âxito!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZyHBjU-R-wi"
   },
   "source": [
    "### **Baseline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WZ8G01aSBYX"
   },
   "source": [
    "En este punto esperamos que tengan conocimiento sobre redes neuronales y en particular redes neuronales recurrentes (RNN), si no siempre pueden escribirnos por el canal de Discord para aclarar dudas. La RNN del baseline adjunto a este notebook est√° programado en la librer√≠a [`pytorch`](https://pytorch.org/) pero ustedes pueden utilizar keras, tensorflow si as√≠ lo desean. El c√≥digo contiene lo siguiente:\n",
    "\n",
    "- La carga de los datasets, creaci√≥n de batches de texto y padding (esto es importante ya que si utilizan redes neuronales tienen que tener el mismo largo los inputs). \n",
    "\n",
    "- La implementaci√≥n b√°sica de una red `LSTM` simple de solo un nivel y sin bi-direccionalidad. \n",
    "\n",
    "- La construcci√≥n del formato del output requerido para que lo puedan probar en la tarea en codalab.\n",
    "\n",
    "Se espera que como m√≠nimo ustedes puedan experimentar con el baseline utilizando (pero no limit√°ndose) estas sugerencias:\n",
    "\n",
    "*   Probar la t√©cnica de early stopping.\n",
    "*   Variar la cantidad de par√°metros de la capa de embeddings.\n",
    "*   Variar la cantidad de capas RNN.\n",
    "*   Variar la cantidad de par√°metros de las capas de RNN.\n",
    "*   Inicializar la capa de embeddings con modelos pre-entrenados. (word2vec, glove, conceptnet, etc...). [Embeddings en espa√±ol aqu√≠](https://github.com/dccuchile/spanish-word-embeddings). Tambi√©n aqu√≠ pueden encontrar unos embeddings cl√≠nicos en Espa√±ol: [https://zenodo.org/record/3924799](https://zenodo.org/record/3924799)\n",
    "*   Variar la cantidad de √©pocas de entrenamiento.\n",
    "*   Variar el optimizador, learning rate, batch size, usar CRF loss, etc.\n",
    "*   Probar una capa de CRF para garantizar el     formato IOB2.\n",
    "*   Probar bi-direccionalidad.\n",
    "*   Incluir dropout.\n",
    "*   Probar modelos de tipo GRU.\n",
    "*   Probar usando capas de atenci√≥n.\n",
    "*   Probar Embedding Contextuales (les puede ser de utilidad [flair](https://github.com/flairNLP/flair))\n",
    "*   Probar modelos de transformers en espa√±ol usando [Huggingface](https://github.com/huggingface/transformers) o el framework Flair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Rr2mzxPTzNd"
   },
   "source": [
    "### **Reporte**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEf33mnxT0rf"
   },
   "source": [
    "Este debe cumplir la siguiente estructura:\n",
    "\n",
    "1.\t**Introducci√≥n**: Presentar brevemente el contexto, problema a resolver, incluyendo la formalizaci√≥n de la task (c√≥mo son los inputs y outputs del problema) y los desaf√≠os que ven al analizar el corpus entregado. (**0.5 puntos**)\n",
    "\n",
    "2.\t**Modelos**: Describir brevemente los modelos, m√©todos e hiperpar√°metros utilizados. (**1.0 puntos**)\n",
    "\n",
    "4.\t**M√©tricas de evaluaci√≥n**: Describir las m√©tricas utilizadas en la evaluaci√≥n indicando qu√© miden y cu√°l es su interpretaci√≥n en este problema en particular. (**0.5 puntos**)\n",
    "\n",
    "5.  **Dise√±o experimental**: Esta es una de las secciones m√°s importantes del reporte. Deben describir minuciosamente los experimentos que realizar√°n en la siguiente secci√≥n. Describir las variables de control que manejar√°n, algunos ejemplos pueden ser: Los hiperpar√°metros de los modelos, tipo de embeddings utilizados, tipos de arquitecturas. Ser claros con el conjunto de hiperpar√°metros que probar√°n, la decisi√≥n en las funciones de optimizaci√≥n, funci√≥n de p√©rdida,  regulaci√≥n, etc. B√°sicamente explicar qu√© es lo que veremos en la siguiente secci√≥n.\n",
    "(**1 punto**)\n",
    "\n",
    "6.\t**Experimentos**: Reportar todos sus experimentos y c√≥digo en esta secci√≥n. Comparar los resultados obtenidos utilizando diferentes modelos. ¬°Es vital haber realizado varios experimentos para sacar una buena nota! (**2.0 puntos**)\n",
    "\n",
    "7.\t**Conclusiones**: Discutir resultados, proponer trabajo futuro. (**1 punto**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaoU1EXfUDbl"
   },
   "source": [
    "# **Entregable.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzQlYlmGaSFH"
   },
   "source": [
    "## **Introducci√≥n**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVL0-01AUOzL"
   },
   "source": [
    "    Escriba su introducci√≥n aqu√≠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbA1EmhCaSFI"
   },
   "source": [
    "## **Modelos**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HsvlfPJUSId"
   },
   "source": [
    "    Explique claramente los modelos utilizados aqu√≠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaVhZ5iaaSFK"
   },
   "source": [
    "## **M√©tricas de evaluaci√≥n**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXl3GaVMUYA7"
   },
   "source": [
    "- **M√©trica estricta:**\n",
    "- **Precision:** \n",
    "- **Recall:** \n",
    "- **Micro F1 score:**\n",
    "Recuerde hacer la distinci√≥n entre lo que ser√≠a una m√©trica de micro f1-score vs macro f1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u27WffRVUj4v"
   },
   "source": [
    "## **Dise√±o experimental**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3O228DbeUmE7"
   },
   "source": [
    "    Descripci√≥n de la metodolog√≠a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFM-wNt8aSFM"
   },
   "source": [
    "## **Experimentos**\n",
    "\n",
    "\n",
    "El c√≥digo que les entregaremos servir√° de baseline para luego implementar mejores modelos. \n",
    "En general, el c√≥digo asociado a la carga de los datos, las funciones de entrenamiento, de evaluaci√≥n y la predicci√≥n de los datos de la competencia no deber√≠an cambiar. \n",
    "Solo deben preocuparse de cambiar la arquitectura del modelo, sus hiperpar√°metros y reportar, lo cual lo pueden hacer en las subsecciones *modelos*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMgKjfYC_Go-"
   },
   "source": [
    "###  **Carga de datos y Preprocesamiento**\n",
    "\n",
    "Para cargar los datos y preprocesarlos usaremos la librer√≠a [`torchtext`](https://github.com/pytorch/text). Tener cuidado ya que hace algunos meses esta librer√≠a tuvo cambios radicales, quedando las funcionalidades pasadas en un nuevo paquete llamado legacy. Esto ya que si quieren usar m√°s funciones de la librer√≠a entonces vean los cambios en la documentaci√≥n.\n",
    "\n",
    "En particular usaremos su m√≥dulo `data`, el cual seg√∫n su documentaci√≥n original provee: \n",
    "\n",
    "    - Ability to describe declaratively how to load a custom NLP dataset that's in a \"normal\" format\n",
    "    - Ability to define a preprocessing pipeline\n",
    "    - Batching, padding, and numericalizing (including building a vocabulary object)\n",
    "    - Wrapper for dataset splits (train, validation, test)\n",
    "\n",
    "\n",
    "El proceso ser√° el siguiente: \n",
    "\n",
    "1. Descargar los datos desde github y examinarlos.\n",
    "2. Definir los campos (`fields`) que cargaremos desde los archivos.\n",
    "3. Cargar los datasets.\n",
    "4. Crear el vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27csY87GaSFO",
    "outputId": "ea0b8aac-8179-40da-e765-9be28d94d3e8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Downloading torchtext-0.12.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: requests in c:\\users\\felip\\anaconda3\\lib\\site-packages (from torchtext) (2.27.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\felip\\anaconda3\\lib\\site-packages (from torchtext) (1.21.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\felip\\anaconda3\\lib\\site-packages (from torchtext) (4.62.3)\n",
      "Requirement already satisfied: torch==1.11.0 in c:\\users\\felip\\anaconda3\\lib\\site-packages (from torchtext) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\felip\\anaconda3\\lib\\site-packages (from torch==1.11.0->torchtext) (3.10.0.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\felip\\anaconda3\\lib\\site-packages (from requests->torchtext) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\felip\\anaconda3\\lib\\site-packages (from requests->torchtext) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\felip\\anaconda3\\lib\\site-packages (from requests->torchtext) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\felip\\anaconda3\\lib\\site-packages (from requests->torchtext) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\felip\\anaconda3\\lib\\site-packages (from tqdm->torchtext) (0.4.4)\n",
      "Installing collected packages: torchtext\n",
      "Successfully installed torchtext-0.12.0\n"
     ]
    }
   ],
   "source": [
    "# Instalamos torchtext que nos facilitar√° la vida en el pre-procesamiento del formato ConLL.\n",
    "!pip3 install --upgrade torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext==0.9.0\n",
      "  Downloading torchtext-0.9.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Collecting torch==1.8.0\n",
      "  Downloading torch-1.8.0-cp38-cp38-win_amd64.whl (190.5 MB)\n",
      "Requirement already satisfied: requests in c:\\users\\felip\\anaconda3\\lib\\site-packages (from torchtext==0.9.0) (2.27.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\felip\\anaconda3\\lib\\site-packages (from torchtext==0.9.0) (1.21.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\felip\\anaconda3\\lib\\site-packages (from torchtext==0.9.0) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\felip\\anaconda3\\lib\\site-packages (from torch==1.8.0->torchtext==0.9.0) (3.10.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\felip\\anaconda3\\lib\\site-packages (from requests->torchtext==0.9.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\felip\\anaconda3\\lib\\site-packages (from requests->torchtext==0.9.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\felip\\anaconda3\\lib\\site-packages (from requests->torchtext==0.9.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\felip\\anaconda3\\lib\\site-packages (from requests->torchtext==0.9.0) (1.26.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\felip\\anaconda3\\lib\\site-packages (from tqdm->torchtext==0.9.0) (0.4.4)\n",
      "Installing collected packages: torch, torchtext\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.11.0\n",
      "    Uninstalling torch-1.11.0:\n",
      "      Successfully uninstalled torch-1.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Acceso denegado: 'C:\\\\Users\\\\felip\\\\anaconda3\\\\Lib\\\\site-packages\\\\~orch\\\\lib\\\\asmjit.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instalamos torchtext que nos facilitar√° la vida en el pre-procesamiento del formato ConLL.\n",
    "!pip3 install torchtext==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ng7wRGEyawjM"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'legacy' from 'torchtext' (C:\\Users\\felip\\anaconda3\\lib\\site-packages\\torchtext\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16088/739313335.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlegacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Garantizar reproducibilidad de los experimentos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'legacy' from 'torchtext' (C:\\Users\\felip\\anaconda3\\lib\\site-packages\\torchtext\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext import data, datasets, legacy\n",
    "\n",
    "\n",
    "# Garantizar reproducibilidad de los experimentos\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BehSou6rCvwg"
   },
   "source": [
    "#### **Obtener datos**\n",
    "\n",
    "Descargamos los datos de entrenamiento, validaci√≥n y prueba en nuestro directorio de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lbT0g_kC18Jb",
    "outputId": "61d2e285-73e4-4e95-fa1f-de072bbb503e"
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "\n",
    "!wget https://github.com/dccuchile/CC6205/releases/download/v1.0/train.txt -nc # Dataset de Entrenamiento\n",
    "!wget https://github.com/dccuchile/CC6205/releases/download/v1.0/dev.txt -nc    # Dataset de Validaci√≥n (Para probar y ajustar el modelo)\n",
    "!wget https://github.com/dccuchile/CC6205/releases/download/v1.0/test.txt -nc  # Dataset de la Competencia. Estos datos solo contienen los tokens. ¬°¬°SON LOS QUE DEBEN SER PREDICHOS!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMud7YGMBZvg"
   },
   "source": [
    "####  **Fields**\n",
    "\n",
    "Un `field`:\n",
    "\n",
    "* Define un tipo de datos junto con instrucciones para convertir el texto a Tensor.\n",
    "* Contiene un objeto `Vocab` que contiene el vocabulario (palabras posibles que puede tomar ese campo).\n",
    "* Contiene otros par√°metros relacionados con la forma en que se debe numericalizar un tipo de datos, como un m√©todo de tokenizaci√≥n y el tipo de Tensor que se debe producir.\n",
    "\n",
    "\n",
    "Analizemos el siguiente cuadro el cual contiene un ejemplo cualquiera de entrenamiento:\n",
    "\n",
    "\n",
    "```\n",
    "El O\n",
    "paciente O\n",
    "padece O\n",
    "de O\n",
    "cancer B-Disease\n",
    "de I-Disease\n",
    "colon I-Disease\n",
    ". O\n",
    "```\n",
    "\n",
    "Cada linea contiene un token y el tipo de entidad asociado en el formato IOB2 ya explicado. Para que `torchtext` pueda cargar estos datos, debemos definir como va a leer y separar los componentes de cada una de las lineas.\n",
    "Para esto, definiremos un field para cada uno de esos componentes: Las palabras (`TEXT`) y las etiquetas o categor√≠as (`NER_TAGS`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DcM_IjgCdzz"
   },
   "outputs": [],
   "source": [
    "# Primer Field: TEXT. Representan los tokens de la secuencia\n",
    "TEXT = legacy.data.Field(lower=False) \n",
    "\n",
    "# Segundo Field: NER_TAGS. Representan los Tags asociados a cada palabra.\n",
    "NER_TAGS = legacy.data.Field(unk_token=None)\n",
    "fields = ((\"text\", TEXT), (\"nertags\", NER_TAGS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCKTJOdgC5eC"
   },
   "source": [
    "####  **SequenceTaggingDataset**\n",
    "\n",
    "`SequenceTaggingDataset` es una clase de torchtext dise√±ada para contener datasets de sequence labeling. Los ejemplos que se guarden en una instancia de estos ser√°n arreglos de palabras asociados con sus respectivos tags.\n",
    "\n",
    "Por ejemplo, para Part-of-speech tagging:\n",
    "\n",
    "[I, love, PyTorch, .] estar√° asociado con [PRON, VERB, PROPN, PUNCT]\n",
    "\n",
    "\n",
    "La idea es que usando los fields que definimos antes, le indiquemos a la clase c√≥mo cargar los datasets de prueba, validaci√≥n y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HsHdGml62J21"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = legacy.datasets.SequenceTaggingDataset.splits(\n",
    "    path=\"./\",\n",
    "    train=\"train.txt\",\n",
    "    validation=\"dev.txt\",\n",
    "    test=\"test.txt\",\n",
    "    fields=fields,\n",
    "    encoding=\"utf-8\",\n",
    "    separator=\" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hu7q3HCliia5",
    "outputId": "e3a0c06f-4c6a-4b6c-db30-ecea007cc4d8"
   },
   "outputs": [],
   "source": [
    "print(f\"Numero de ejemplos de entrenamiento: {len(train_data)}\")\n",
    "print(f\"N√∫mero de ejemplos de validaci√≥n: {len(valid_data)}\")\n",
    "print(f\"N√∫mero de ejemplos de test (competencia): {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDRnhXAdFGL-"
   },
   "source": [
    "Visualizemos un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T023Ld4RaSF4",
    "outputId": "9d69b2d5-f6e8-4d0c-e8cb-a49d4d919bf4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random_item_idx = random.randint(0, len(train_data))\n",
    "random_example = train_data.examples[random_item_idx]\n",
    "list(zip(random_example.text, random_example.nertags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2l05KYy5FSUy"
   },
   "source": [
    "#### **Construir los vocabularios para el texto y las etiquetas**\n",
    "\n",
    "Los vocabularios son los objetos que contienen todos los tokens (de entrenamiento) posibles para ambos fields. El siguiente paso consiste en construirlos. Para esto, hacemos uso del m√©todo `Field.build_vocab` sobre cada uno de nuestros `fields`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PBhp7WICiibL"
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data)\n",
    "NER_TAGS.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M4OgUKM_iibO",
    "outputId": "de41785a-e21e-4f60-cdf1-9a8870791695",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Tokens √∫nicos en TEXT: {len(TEXT.vocab)}\")\n",
    "print(f\"Tokens √∫nicos en NER_TAGS: {len(NER_TAGS.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4FeyL9nFnId",
    "outputId": "eba139cb-b827-4004-9b7d-15c082d4ba65"
   },
   "outputs": [],
   "source": [
    "#Veamos las posibles etiquetas que hemos cargado:\n",
    "NER_TAGS.vocab.itos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYQDoUqSHFKj"
   },
   "source": [
    "Observen que ademas de los tags NER, tenemos \\<pad\\>, el cual es generado por el dataloader para cumplir con el padding de cada oraci√≥n.\n",
    "\n",
    "Veamos ahora los tokens mas frecuentes y especiales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m5eSLm4diibR",
    "outputId": "23bd68af-b5a9-4c67-d30d-9da65eb2eeed"
   },
   "outputs": [],
   "source": [
    "# Tokens mas frecuentes (Ser√° necesario usar stopwords, eliminar s√≠mbolos o nos entregan informaci√≥n (?) )\n",
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDyNLMPz9duD"
   },
   "outputs": [],
   "source": [
    "# Seteamos algunas variables que nos ser√°n de utilidad mas adelante...\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "PAD_TAG_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
    "O_TAG_IDX = NER_TAGS.vocab.stoi['O']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrYvF3X0sjWL"
   },
   "source": [
    "#### **Frecuencia de los Tags**\n",
    "\n",
    "Visualizemos r√°pidamente las cantidades y frecuencias de cada tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tuXOsbJUiibh",
    "outputId": "117e7fcd-7553-41b6-b9b6-a4e43e3a6d44"
   },
   "outputs": [],
   "source": [
    "def tag_percentage(tag_counts):\n",
    "    \n",
    "    total_count = sum([count for tag, count in tag_counts])\n",
    "    tag_counts_percentages = [(tag, count, count/total_count) for tag, count in tag_counts]\n",
    "  \n",
    "    return tag_counts_percentages\n",
    "\n",
    "print(\"Tag Ocurrencia Porcentaje\\n\")\n",
    "\n",
    "for tag, count, percent in tag_percentage(NER_TAGS.vocab.freqs.most_common()):\n",
    "    print(f\"{tag}\\t{count}\\t{percent*100:4.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4wPiydnaSGs"
   },
   "source": [
    "#### **Configuramos pytorch y dividimos los datos.**\n",
    "\n",
    "Importante: si tienes problemas con la ram de la gpu, disminuye el tama√±o de los batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uB7cwLWpaSGs",
    "outputId": "0295f73c-8339-455a-ecee-3a8a91fdc46c"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16  # disminuir si hay problemas de ram.\n",
    "\n",
    "# Usar cuda si es que est√° disponible.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using', device)\n",
    "\n",
    "# Dividir datos entre entrenamiento y test. Si van a hacer alg√∫n sort no puede ser sobre\n",
    "# el conjunto de testing ya que al hacer sus predicciones sobre el conjunto de test sin etiquetas\n",
    "# debe conservar el orden original para ser comparado con los golden_labels. \n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = legacy.data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    sort=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B21E1eAFId16"
   },
   "source": [
    "#### **M√©tricas de evaluaci√≥n**\n",
    "\n",
    "Adem√°s, definiremos las m√©tricas que ser√°n usadas tanto para la competencia como para evaluar el modelo: `precision`, `recall` y `micro f1-score`.\n",
    "**Importante**: Noten que la evaluaci√≥n solo se hace para las Named Entities (sin contar 'O'), toda esta funcionalidad nos la entrega la librer√≠a seqeval, pueden revisar m√°s documentaci√≥n aqu√≠: https://github.com/chakki-works/seqeval. No utilicen el c√≥digo entregado por sklearn para calcular las m√©tricas ya que esta lo hace a nivel de token y no a nivel de entidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o63ov69_rX2T",
    "outputId": "aadbfed7-8f3a-4a5c-9ef9-19aec2664907"
   },
   "outputs": [],
   "source": [
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9mUOOLEWiicU"
   },
   "outputs": [],
   "source": [
    "# Definimos las m√©tricas\n",
    "\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def calculate_metrics(preds, y_true, pad_idx=PAD_TAG_IDX, o_idx=O_TAG_IDX):\n",
    "    \"\"\"\n",
    "    Calcula precision, recall y f1 de cada batch.\n",
    "    \"\"\"\n",
    "\n",
    "    # Obtener el indice de la clase con probabilidad mayor. (clases)\n",
    "    y_pred = preds.argmax(dim=1, keepdim=True)\n",
    "\n",
    "    # filtramos <pad> para calcular los scores.\n",
    "    mask = [(y_true != pad_idx)]\n",
    "    y_pred = y_pred[mask]\n",
    "    y_true = y_true[mask]\n",
    "\n",
    "    # traemos a la cpu\n",
    "    y_pred = y_pred.view(-1).to('cpu').numpy()\n",
    "    y_true = y_true.to('cpu').numpy()\n",
    "    y_pred = [[NER_TAGS.vocab.itos[v] for v in y_pred]]\n",
    "    y_true = [[NER_TAGS.vocab.itos[v] for v in y_true]]\n",
    "    \n",
    "    # calcular scores\n",
    "    f1 = f1_score(y_true, y_pred, mode='strict')\n",
    "    precision = precision_score(y_true, y_pred, mode='strict')\n",
    "    recall = recall_score(y_true, y_pred, mode='strict')\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hod516H1aSG2"
   },
   "source": [
    "-------------------\n",
    "\n",
    "### **Modelo Baseline**\n",
    "\n",
    "Teniendo ya cargado los datos, toca definir nuestro modelo. Este baseline tendr√° una capa de embedding, unas cuantas LSTM y una capa de salida y usar√° dropout en el entrenamiento.\n",
    "\n",
    "Este constar√° de los siguientes pasos: \n",
    "\n",
    "1. Definir la clase que contendr√° la red.\n",
    "2. Definir los hiperpar√°metros e inicializar la red. \n",
    "3. Definir el n√∫mero de √©pocas de entrenamiento\n",
    "4. Definir la funci√≥n de loss.\n",
    "\n",
    "\n",
    "\n",
    "Recomendamos que para experimentar, encapsules los modelos en una sola variable y luego la fijes en model para entrenarla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMPL08XqaSG3"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Definir la red\n",
    "class NER_RNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 embedding_dim, \n",
    "                 hidden_dim, \n",
    "                 output_dim,\n",
    "                 n_layers, \n",
    "                 bidirectional, \n",
    "                 dropout, \n",
    "                 pad_idx):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Capa de embedding\n",
    "        self.embedding = nn.Embedding(input_dim,\n",
    "                                      embedding_dim,\n",
    "                                      padding_idx=pad_idx)\n",
    "\n",
    "        # Capa LSTM\n",
    "        self.lstm = nn.LSTM(embedding_dim,\n",
    "                           hidden_dim,\n",
    "                           num_layers=n_layers,\n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout = dropout if n_layers > 1 else 0)\n",
    "\n",
    "        # Capa de salida\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
    "                            output_dim)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "\n",
    "        #text = [sent len, batch size]\n",
    "\n",
    "        # Convertir lo enviado a embedding\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        \n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "\n",
    "        # Pasar los embeddings por la rnn (LSTM)\n",
    "\n",
    "        #output = [sent len, batch size, hid dim * n directions]\n",
    "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
    "\n",
    "        # Predecir usando la capa de salida.\n",
    "        predictions = self.fc(self.dropout(outputs))\n",
    "        #predictions = [sent len, batch size, output dim]\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCl3530VaSG7"
   },
   "source": [
    "#### **Hiperpar√°metros de la red**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHdi3QdOaSG8"
   },
   "outputs": [],
   "source": [
    "# tama√±o del vocabulario. recuerden que la entrada son vectores bag of word(one-hot).\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 200  # dimensi√≥n de los embeddings.\n",
    "HIDDEN_DIM = 128  # dimensi√≥n de la capas LSTM\n",
    "OUTPUT_DIM = len(NER_TAGS.vocab)  # n√∫mero de clases\n",
    "\n",
    "N_LAYERS = 3  # n√∫mero de capas.\n",
    "DROPOUT = 0.5\n",
    "BIDIRECTIONAL = False\n",
    "\n",
    "# Creamos nuestro modelo.\n",
    "baseline_model = NER_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
    "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
    "\n",
    "baseline_model_name = 'baseline'  # nombre que tendr√° el modelo guardado..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jlF1DhJeaSHA"
   },
   "outputs": [],
   "source": [
    "baseline_n_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3u4imJGaSHE"
   },
   "source": [
    "#### Definimos la funci√≥n de loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6G_4k99_aSHG"
   },
   "outputs": [],
   "source": [
    "# Loss: Cross Entropy\n",
    "TAG_PAD_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
    "baseline_criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRYOEDiQaSHK"
   },
   "source": [
    "--------------------\n",
    "### Modelo 1\n",
    "\n",
    "En estas secciones pueden implementar nuevas redes al modificar los hiperpar√°metros, la cantidad de √©pocas de entrenamiento, el tama√±o de los batches, loss, optimizador, etc... como tambi√©n definir nuevas arquitecturas de red (mediante la creaci√≥n de clases nuevas)\n",
    "\n",
    "\n",
    "Al final de estas, hay 4 variables, las cuales deben setear con los modelos, √©pocas de entrenamiento, loss y optimizador que deseen probar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c81f8ki5aSHL"
   },
   "outputs": [],
   "source": [
    "# model_1 = ...\n",
    "# model_name_1 = ...\n",
    "# n_epochs_1 = ...\n",
    "# loss_1 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rV9oLkN1aSHO"
   },
   "source": [
    "---------------\n",
    "\n",
    "### Modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KWPzETaNaSHP"
   },
   "outputs": [],
   "source": [
    "# model_2 = ...\n",
    "# model_name_2 = ...\n",
    "# n_epochs_2 = ...\n",
    "# loss_2 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zpy3p7YaaSHT"
   },
   "source": [
    "---------------\n",
    "\n",
    "\n",
    "### Modelo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_w0CFjA8aSHU"
   },
   "outputs": [],
   "source": [
    "# modelo_3 = ...\n",
    "# model_name_3 = ...\n",
    "# n_epochs_3 = ...\n",
    "# loss_3 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPGdirx7aSHZ"
   },
   "source": [
    "------\n",
    "### **Entrenamos y evaluamos**\n",
    "\n",
    "\n",
    "**Importante** : Fijen el modelo, el n√∫mero de √©pocas de entrenamiento, la loss y el optimizador que usar√°n para entrenar y evaluar en las siguientes variables!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r8YlGnjxaSHZ"
   },
   "outputs": [],
   "source": [
    "model = baseline_model\n",
    "model_name = baseline_model_name\n",
    "criterion = baseline_criterion\n",
    "n_epochs = baseline_n_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pu_lXic2aSHd"
   },
   "source": [
    "\n",
    "\n",
    "#### **Inicializamos la red**\n",
    "\n",
    "Iniciamos los pesos de la red de forma aleatoria (Usando una distribuci√≥n normal).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-G_NWFcaSHe",
    "outputId": "0b3d98ec-e443-4f27-c4b2-efbfc75ff49b"
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    # Inicializamos los pesos como aleatorios\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean=0, std=0.1) \n",
    "        \n",
    "    # Seteamos como 0 los embeddings de UNK y PAD.\n",
    "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjWDX2CJaSHh",
    "outputId": "4e14a084-285e-463b-b859-8554df3dc2e8"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'El modelo actual tiene {count_parameters(model):,} par√°metros entrenables.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVqBqerlaSHk"
   },
   "source": [
    "Notar que definimos los embeddings que representan a \\<unk\\> y \\<pad\\>  como [0, 0, ..., 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVZvHtwpaSHq"
   },
   "source": [
    "#### **Definimos el optimizador**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AH6o8_cTaSHq"
   },
   "outputs": [],
   "source": [
    "# Optimizador\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fz39wa78wGYR"
   },
   "source": [
    "#### **Enviamos el modelo a cuda**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dqr0AJ6_iicR"
   },
   "outputs": [],
   "source": [
    "# Enviamos el modelo y la loss a cuda (en el caso en que est√© disponible)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xlq48WjiW6U"
   },
   "source": [
    "#### **Definimos el entrenamiento de la red**\n",
    "\n",
    "Algunos conceptos previos: \n",
    "\n",
    "- `epoch` : una pasada de entrenamiento completa de una dataset.\n",
    "- `batch`: una fracci√≥n de la √©poca. Se utilizan para entrenar mas r√°pidamente la red. (mas eficiente pasar n datos que uno en cada ejecuci√≥n del backpropagation)\n",
    "\n",
    "Esta funci√≥n est√° encargada de entrenar la red en una √©poca. Para esto, por cada batch de la √©poca actual, predice los tags del texto, calcula su loss y luego hace backpropagation para actualizar los pesos de la red.\n",
    "\n",
    "Observaci√≥n: En algunos comentarios aparecer√° el tama√±o de los tensores entre corchetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DV6YLt0oiicW"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_precision = 0\n",
    "    epoch_recall = 0\n",
    "    epoch_f1 = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Por cada batch del iterador de la √©poca:\n",
    "    for batch in iterator:\n",
    "\n",
    "        # Extraemos el texto y los tags del batch que estamos procesado\n",
    "        text = batch.text\n",
    "        tags = batch.nertags\n",
    "\n",
    "        # Reiniciamos los gradientes calculados en la iteraci√≥n anterior\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #text = [sent len, batch size]\n",
    "\n",
    "        # Predecimos los tags del texto del batch.\n",
    "        predictions = model(text)\n",
    "\n",
    "        #predictions = [sent len, batch size, output dim]\n",
    "        #tags = [sent len, batch size]\n",
    "\n",
    "        # Reordenamos los datos para calcular la loss\n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "\n",
    "        #predictions = [sent len * batch size, output dim]\n",
    "\n",
    "\n",
    "\n",
    "        # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n",
    "        loss = criterion(predictions, tags)\n",
    "        \n",
    "        # Calculamos el accuracy\n",
    "        precision, recall, f1 = calculate_metrics(predictions, tags)\n",
    "\n",
    "        # Calculamos los gradientes\n",
    "        loss.backward()\n",
    "\n",
    "        # Actualizamos los par√°metros de la red\n",
    "        optimizer.step()\n",
    "\n",
    "        # Actualizamos el loss y las m√©tricas\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_precision += precision\n",
    "        epoch_recall += recall\n",
    "        epoch_f1 += f1\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_precision / len(\n",
    "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYNcwKnAz5Hf"
   },
   "source": [
    "#### **Definimos la funci√≥n de evaluaci√≥n**\n",
    "\n",
    "Evalua el rendimiento actual de la red usando los datos de validaci√≥n. \n",
    "\n",
    "Por cada batch de estos datos, calcula y reporta el loss y las m√©tricas asociadas al conjunto de validaci√≥n. \n",
    "Ya que las m√©tricas son calculadas por cada batch, estas son retornadas promediadas por el n√∫mero de batches entregados. (ver linea del return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsRuiUuHiicY"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_precision = 0\n",
    "    epoch_recall = 0\n",
    "    epoch_f1 = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Indicamos que ahora no guardaremos los gradientes\n",
    "    with torch.no_grad():\n",
    "        # Por cada batch\n",
    "        for batch in iterator:\n",
    "\n",
    "            text = batch.text\n",
    "            tags = batch.nertags\n",
    "\n",
    "            # Predecimos\n",
    "            predictions = model(text)\n",
    "\n",
    "            predictions = predictions.view(-1, predictions.shape[-1])\n",
    "            tags = tags.view(-1)\n",
    "\n",
    "            # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n",
    "            loss = criterion(predictions, tags)\n",
    "\n",
    "            # Calculamos las m√©tricas\n",
    "            precision, recall, f1 = calculate_metrics(predictions, tags)\n",
    "\n",
    "            # Actualizamos el loss y las m√©tricas\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_precision += precision\n",
    "            epoch_recall += recall\n",
    "            epoch_f1 += f1\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_precision / len(\n",
    "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xs-n9Y5yiica"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hy3MVf5H0A94"
   },
   "source": [
    "\n",
    "#### **Entrenamiento de la red**\n",
    "\n",
    "En este cuadro de c√≥digo ejecutaremos el entrenamiento de la red.\n",
    "Para esto, primero definiremos el n√∫mero de √©pocas y luego por cada √©poca, ejecutaremos `train` y `evaluate`.\n",
    "\n",
    "**Importante: Reiniciar los pesos del modelo**\n",
    "\n",
    "Si ejecutas nuevamente esta celda, se seguira entrenando el mismo modelo una y otra vez. \n",
    "Para reiniciar el modelo se debe ejecutar nuevamente la celda que contiene la funci√≥n `init_weights`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iK5lQqpviicf",
    "outputId": "0880b2a1-7386-4277-f863-afd343c8cd13"
   },
   "outputs": [],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Recuerdo: train_iterator y valid_iterator contienen el dataset dividido en batches.\n",
    "\n",
    "    # Entrenar\n",
    "    train_loss, train_precision, train_recall, train_f1 = train(\n",
    "        model, train_iterator, optimizer, criterion)\n",
    "\n",
    "    # Evaluar (valid = validaci√≥n)\n",
    "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
    "        model, valid_iterator, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    # Si obtuvimos mejores resultados, guardamos este modelo en el almacenamiento (para poder cargarlo luego)\n",
    "    # Si detienen el entrenamiento prematuramente, pueden cargar el modelo en el siguiente recuadro de c√≥digo.\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
    "    # Si ya no mejoramos el loss de validaci√≥n, terminamos de entrenar.\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(\n",
    "        f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
    "    )\n",
    "    print(\n",
    "        f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcZPraG-9duO"
   },
   "source": [
    "**Importante**: Recuerden que el √∫ltimo modelo entrenado no es el mejor (probablemente est√© *overfitteado*), si no el que guardamos con la menor loss del conjunto de validaci√≥n. Este problema lo pueden solucionar con *early stopping*.\n",
    "Para cargar el mejor modelo entrenado, ejecuten la siguiente celda.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y27CNYfrjtQ-"
   },
   "outputs": [],
   "source": [
    "# cargar el mejor modelo entrenado.\n",
    "model.load_state_dict(torch.load('{}.pt'.format(model_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLuqFKFR9duO"
   },
   "outputs": [],
   "source": [
    "# Limpiar ram de cuda\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBctQHTh0lxD"
   },
   "source": [
    "#### **Evaluamos el set de validaci√≥n con el modelo final**\n",
    "\n",
    "Estos son los resultados de predecir el dataset de evaluaci√≥n con el *mejor* modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0gVbP8yiicj"
   },
   "outputs": [],
   "source": [
    "valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
    "    model, valid_iterator, criterion)\n",
    "\n",
    "print(\n",
    "    f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uF1ysw_Kw6zz"
   },
   "source": [
    "### **Predecir datos para la competencia**\n",
    "\n",
    "Ahora, a partir de los datos de **test** y nuestro modelo entrenado, vamos a predecir las etiquetas que ser√°n evaluadas en la competencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1RBs3UU4wLk3"
   },
   "outputs": [],
   "source": [
    "def predict_labels(model, iterator, criterion, fields=fields):\n",
    "\n",
    "    # Extraemos los vocabularios.\n",
    "    text_field = fields[0][1]\n",
    "    nertags_field = fields[1][1]\n",
    "    tags_vocab = nertags_field.vocab.itos\n",
    "    words_vocab = text_field.vocab.itos\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in iterator:\n",
    "\n",
    "            text_batch = batch.text\n",
    "            text_batch = torch.transpose(text_batch, 0, 1).tolist()\n",
    "\n",
    "            # Predecir los tags de las sentences del batch\n",
    "            predictions_batch = model(batch.text)\n",
    "            predictions_batch = torch.transpose(predictions_batch, 0, 1)\n",
    "\n",
    "            # por cada oraci√≥n predicha:\n",
    "            for sentence, sentence_prediction in zip(text_batch,\n",
    "                                                     predictions_batch):\n",
    "                for word_idx, word_predictions in zip(sentence,\n",
    "                                                      sentence_prediction):\n",
    "                    # Obtener el indice del tag con la probabilidad mas alta.\n",
    "                    argmax_index = word_predictions.topk(1)[1]\n",
    "\n",
    "                    current_tag = tags_vocab[argmax_index]\n",
    "                    # Obtenemos la palabra\n",
    "                    current_word = words_vocab[word_idx]\n",
    "\n",
    "                    if current_word != '<pad>':\n",
    "                        predictions.append([current_word, current_tag])\n",
    "                predictions.append(['EOS', 'EOS'])\n",
    "\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "predictions = predict_labels(model, test_iterator, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwQp1Ru8Oht8"
   },
   "source": [
    "### **Generar el archivo para la submission**\n",
    "\n",
    "No hay problema si aparecen unk en la salida. Estos no son relevantes para evaluarlos, usamos solo los tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPfZkjJGkWyq"
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "if (os.path.isfile('./predictions.zip')):\n",
    "    os.remove('./predictions.zip')\n",
    "\n",
    "if (not os.path.isdir('./predictions')):\n",
    "    os.mkdir('./predictions')\n",
    "\n",
    "else:\n",
    "    # Eliminar predicciones anteriores:\n",
    "    shutil.rmtree('./predictions')\n",
    "    os.mkdir('./predictions')\n",
    "\n",
    "f = open('predictions/predictions.txt', 'w')\n",
    "for i, (word, tag) in enumerate(predictions[:-1]):\n",
    "    if word=='EOS' and tag=='EOS': f.write('\\n')\n",
    "    else: \n",
    "      if i == len(predictions[:-1])-1:\n",
    "        f.write(word + ' ' + tag)\n",
    "      else: f.write(word + ' ' + tag + '\\n')\n",
    "\n",
    "f.close()\n",
    "\n",
    "a = shutil.make_archive('predictions', 'zip', './predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZEWJXrNaSIf"
   },
   "source": [
    "## **Conclusiones**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAtK7y43V7Z_"
   },
   "source": [
    "    Escriba aqu√≠ sus conclusiones"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Z0tyIsliieNr",
    "MocJN22HSJ1x",
    "wnjgmvjBSReb",
    "iWlfabmkaSE7",
    "PzQlYlmGaSFH",
    "UbA1EmhCaSFI",
    "AaVhZ5iaaSFK",
    "u27WffRVUj4v",
    "lRYOEDiQaSHK",
    "rV9oLkN1aSHO",
    "Zpy3p7YaaSHT",
    "Pu_lXic2aSHd",
    "rVZvHtwpaSHq",
    "Fz39wa78wGYR",
    "8xlq48WjiW6U",
    "PYNcwKnAz5Hf",
    "uF1ysw_Kw6zz",
    "YwQp1Ru8Oht8",
    "LZEWJXrNaSIf"
   ],
   "name": "Competencia2_CC6205.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
