{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3559fead",
   "metadata": {},
   "source": [
    "# Competencia 2 NLP : Reconocimiento de entidades (NER) en Espa√±ol\n",
    "\n",
    "**Integrantes:** Alexander Cuevas - Jorge Guti√©rrez - Benjam√≠n Mellado - Felipe Urrutia\n",
    "\n",
    "**Usuario del equipo en CodaLab:** *teamGalactico üåå*\n",
    "\n",
    "**Fecha l√≠mite de entrega üìÜ:** 24 de Junio a las 23:59 hrs.\n",
    "\n",
    "**Tiempo estimado de dedicaci√≥n:** En curso... ‚è≤Ô∏è\n",
    "\n",
    "**Link competencia:** [CC6205 Assignment 2 - Named Entity Recognition (NER) in Spanish](https://codalab.lisn.upsaclay.fr/competitions/5098?secret_key=09955d45-6210-4a35-a171-8050aa050855#learn_the_details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2842ee35",
   "metadata": {},
   "source": [
    "## Introducci√≥n üè∑Ô∏è\n",
    "\n",
    "**REQUIREMENTS: Presentar brevemente el contexto, problema a resolver, incluyendo la formalizaci√≥n de la task (c√≥mo son los inputs y outputs del problema) y los desaf√≠os que ven al analizar el corpus entregado. (0.5 puntos)**\n",
    "\n",
    "En este trabajo utilizaremos el Corpus de Listas de Espera propuesto por [1]. Este corpus esta constituido por derivaciones de diversas consultas de la lista de espera de los hospitales p√∫blicos chilenos. Por su naturaleza, cada una de estas derivaciones es un dato no-estructurado escrito en lenguage natural. Entre los resultados principales de [1] est√° otorgar un Corpus anotado usando texto clinico en espa√±ol.\n",
    "\n",
    "La tarea principal propuesta por [1] es un reconocimiento de entidades nombradas. Tambien conocida como NER, por sus siglas en ingles. Dicha tarea es una de las m√°s populares en NLP. La cual consiste en identificar automaticamente piezas esenciales de informacion (entidades) en el texto. Tradicionalmente, la categoria de entidades a identificar eran nombres de personas, lugares y organizaciones. Actualmente, los tipos de categorias se han expandido a diversos dominios del conocimiento. En este trabajo, las entidades que estudiaremos viven en el contexto de texto clinico. \n",
    "\n",
    "[1] utiliza el esquema Unified Medical Language System (UMLS) para las categorias de entidades. Originalmente, [1] genera un Corpus con siete tipos de entidades: \n",
    "\n",
    "    (1) Finding, (2) Procedure, (3) Family Member, (4) Disease, (5) Body Part, (6) Medication y (7) Abbreviation. \n",
    "    \n",
    "Sin embargo, en este trabajo solo estudiaremos cinco de ellas. Todas excepto (1) y (7). Las anotaciones siguen el esquema IOB2, estandar en NER. Esquema definido como sigue: \n",
    "\n",
    ">*Esquema IOB2*. Consiste en identificar cada token con una etiqueta que indica si pertenece o no a una entidad. Si un token **no** es parte de una entidad, se indican con $\\texttt{O}$ (por la inicial en Ingles de *Fuera*). Sino, este necesariamente es un token de una entidad. Para indicar si el token es el inicio de una entidad, se utiliza el prefijo $\\texttt{B-}$ (por la inicial en Ingles de *Comienzo*). En cambio, si el token es la continuacion de una entidad, se utiliza el prefijo $\\texttt{I-}$ (por la inicial en Ingles de *Dentro*). Un ejemplo de este esquema, es el siguiente: \n",
    "\n",
    "\\begin{align*}\n",
    "&\\texttt{PRESENTA}& &\\texttt{FRACTURA}& &\\texttt{CORONARIA}& &\\texttt{COMPLICADA}& &\\texttt{EN}& &\\quad\\text{(Texto)}\\\\\n",
    "&\\texttt{O}& &\\texttt{B-Disease}& &\\texttt{I-Disease}& &\\texttt{I-Disease}& &\\texttt{O}& &\\quad\\text{(IOB2)}\n",
    "\\end{align*}\n",
    "\n",
    "Tal como se puede observar del ejemplo anterior, si se sigue el esquema de anotamiento IOB2 para la tarea de NER, el problema de reconocimiento de entidades nombradas se transforma en un problema de Sequence-Labeling. Tipo de problema que hemos discutido durante las ultimas unidades del curso. Entre los modelos estudiados estan HMM, CRF, MEMMS, CNN y RNN. En este trabajo, nos focalizaremos en solo modelos neuronales dentro de la familia de las Redes Neuronales Recurrentes (RNN, por sus siglas en Ingles).\n",
    "\n",
    "Ahora bien, el conjunto de datos vienen entregados en un forma estandar para la tarea de NER, denominado ConLL. Este consiste en un archivo de texto con dos columnas y saltos de linea que separan cada secuencia. La primera columna, contiene los tokens de la secuencia. Mientras que la segunda columna, contiene las etiquetas IOB2 asociadas a cada token de la secuencia. Por otro lado, los datos vienen previamente separados en conjuntos de Entrenamiento, Desarrollo y Prueba. Estos conjuntos tiene tama√±os X, Y y Z, resp. Ademas, la proporcion de etiquetas IOB2 son mayoritariamente $\\texttt{O}$. Con una proporcion total de A, B y C, en cada conjunto resp. El segundo tipo de etiqueta IOB2 m√°s frecuente es D, con proporciones E, F y G. Mientras que la etiqueta IOB2 menos frecuente es H, con proporiciones I, J, K. Esta diferencia considerable de proporciones de las etiquetas, se denomina desbalance de datos.\n",
    "\n",
    "Entre las dificultades encontradas para est√° tarea est√°n: (1) Desbalance de etiquetas IOB2, (2) [alguna otra encontrada del analisis exploratorio de datos] y (3) NER en contexto de texto clinico. Consideramos que dichas dificultades son desafiantes de resolver. Es por esto que es de nuestro interes lograr resolver satisfactoriamente esta tarea. En las secciones que siguen se encuentra detalladamente nuestra soluci√≥n. \n",
    "\n",
    "**Referencias**\n",
    "\n",
    "[1] B√°ez, P., Villena, F., Rojas, M., Dur√°n, M., & Dunstan, J. (2020, November). The Chilean Waiting List Corpus: a new resource for clinical named entity recognition in Spanish. In Proceedings of the 3rd clinical natural language processing workshop (pp. 291-300). https://aclanthology.org/2020.clinicalnlp-1.32/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2812ce",
   "metadata": {},
   "source": [
    "## Modelos ü§ñ\n",
    "\n",
    "**REQUIREMENTS: Describir brevemente los modelos, m√©todos e hiperpar√°metros utilizados. (1.0 puntos)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372b0939",
   "metadata": {},
   "source": [
    "## M√©tricas de evaluaci√≥n üìä\n",
    "\n",
    "**REQUIREMENTS: Describir las m√©tricas utilizadas en la evaluaci√≥n indicando qu√© miden y cu√°l es su interpretaci√≥n en este problema en particular. (0.5 puntos)**\n",
    "\n",
    "\n",
    "En un problema de Sequence-labeling, la variable predicha por un modelo predictivo es un vector de etiquetas, donde cada etiqueta est√° asociada a un token en la secuencia del input. Una metrica usual para medir el desempe√±o de un modelo de este tipo determina TP, TN, FP y FN con cada etiqueta independientemente. Sin embargo, en la tarea de NER, el objetivo es reconocer entidades nombradas en el texto. Siendo las entidades, las predicciones importantes del modelo y no las etiquetas individuales en formato IOB2. Por esto, una metrica usual no cuantifica el desempe√±o del modelo para el problema original. Para ser m√°s preciso, existen dos motivos, (1) las etiquetas importantes son aquellas asociadas a las entidades y (2) el modelo debe de reconocer exactamente tanto la ubicacion de la entidad como el tipo de entidad. Una metrica que si logra estas dos cosas, se denominda **metrica estricta**.\n",
    "\n",
    "<!-- \\begin{align*}\n",
    "&\\texttt{PRESENTA}& &\\texttt{FRACTURA}& &\\texttt{CORONARIA}& &\\texttt{COMPLICADA}& &\\texttt{EN}& &\\quad\\text{(Texto)}\\\\\n",
    "&\\texttt{O}& &\\texttt{B-Disease}& &\\texttt{I-Disease}& &\\texttt{I-Disease}& &\\texttt{O}& &\\quad\\text{(IOB2)}\\\\\n",
    "&0& &1& &2& &3& &4& &\\quad\\text{(Indice)}\n",
    "\\end{align*} -->\n",
    "\n",
    "En lo que sigue detallaremos las metricas estrictas utilizadas. Para formalizar su definicion, consideremos $D = (S, T)$ un conjunto de $n$ datos. Donde para cada secuencia $s \\in S$, $t^s \\in T$ corresponden a las etiquetas de $s$. Sin perdida de generalidad, supondremos que toda secuencia es de largo $m$. En la practica, $m$ corresponde al largo maximo de un secuencia dentro del conjunto de datos. Si una secuencia (y sus etiquetas) es de largo menor que $m$, se rellena con $\\texttt{<pad>}$. Consideremos $P$ a las etiquetas predichas, i.e., $p^s \\in P$ es la prediccion de la secuencia $s \\in S$, comparable con las etiquetas reales $t^s \\in T$. Naturalmente, $s_i$ es el i-esimo token de la secuencia $s$. Analogamente, $t^s_i$ para su etiqueta real y $p^s_i$ para la predicha. Se dira que $(l, i, j, c)$ es una entidad valida de tipo $c$ en las etiquetas $l$, si $i\\leq j$, $l_i = \\texttt{B-}c$, para cada $k \\in \\{i+1, ..., j\\}$, $l_k = \\texttt{I-}c$ y, si $j<m$, entonces $l_{j+1} \\neq \\texttt{I-}c$. Denotaremos por $E(l, c)$ al conjunto de las entidades validas de tipo $c$ en las etiquetas $l$. Adicionalmente, denotaremos por $E(L)$ al conjunto de todas las entidades validas segun $L$, i.e.,  $$E(L) = \\bigcup \\{E(l,  c): l \\in L \\text{ y $c$ es un tipo de entidad}\\}$$\n",
    "  \n",
    "* *Precision*. Para un tipo de entidad fija (p.ej. Disease), la precision mide la proporcion de veces que una entidad predicha de tal tipo coincide con la entidad real sobre el total de veces que el modelo predice una entidad con el tipo deseado. En efecto, para una entidad de tipo $c$,\n",
    "\n",
    "$$ \\texttt{Precision}(c) = \\frac{|\\{ (l, i, j, d) \\in E(P): d = c, \\exists s \\in S, l = p^s, (p^s, i, j, c) \\in E(t^s, c)\\}|}{|(l, i, j, d) \\in E(P): d=c |}$$\n",
    "\n",
    "* *Recall*. Para un tipo de entidad fija, el recall mide la proporcion de veces que una entidad predicha de tal tipo coincide con la entidad real sobre el total de entidades del tipo deseado. En efecto, para una entidad de tipo $c$,\n",
    "\n",
    "$$ \\texttt{Recall}(c) = \\frac{|\\{ (l, i, j, d) \\in E(P): d = c, \\exists s\\in S, l=p^s, (p^s, i, j, c) \\in E(t^s, c)\\}|}{|(l, i, j, d) \\in E(T): d=c |}$$\n",
    "\n",
    "* *Micro F1 score*. **Recuerde hacer la distinci√≥n entre lo que ser√≠a una m√©trica de micro f1-score vs macro f1-score.** Para un tipo de entidad fija, la Precision y el Recall, entregan informacion distinta sobre las prediccion para dicho tipo de entidad. El primero, considera falsos-positivos, mientras que el segundo considera falsos-negativos. Una forma de condensar esta informacion en una unica metricas es con el promedio armonico entre Precision y Recall, denominado F1-score. Dicha metrica es condicional al tipo de entidad elegida. Para obtener un F1-score global (que considere todos los tipos de entidades), existen dos aproximaciones: (1) Micro F1-score y (2) Macro F1-score. En palabras simples, (1) es el Accuracy del modelo y (2) Un promedio de F1-score por tipo de entidad. Descartamos Macro F1-score dado que nuestros datos son desbalancedados. Por lo tanto, cada F1-score por clase no son estadisticamente comparables. Nos quedaremos con Micro F1-score, ya que traduce globalmente el desempe√±o del modelo. Para computar esta metrica, se utiliza la tecnica estricta definida anteriormente. En efecto, \n",
    "\n",
    "$$ \\texttt{Micro-F1-score} = \\frac{|\\{ (l, i, j, d) \\in E(P): \\exists s\\in S, l=p^s, (p^s, i, j, d) \\in E(t^s, d)\\}|}{|S|}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b571663",
   "metadata": {},
   "source": [
    "## Dise√±o experimental ‚úèÔ∏è\n",
    "\n",
    "**REQUIREMENTS: Esta es una de las secciones m√°s importantes del reporte. Deben describir minuciosamente los experimentos que realizar√°n en la siguiente secci√≥n. Describir las variables de control que manejar√°n, algunos ejemplos pueden ser: Los hiperpar√°metros de los modelos, tipo de embeddings utilizados, tipos de arquitecturas. Ser claros con el conjunto de hiperpar√°metros que probar√°n, la decisi√≥n en las funciones de optimizaci√≥n, funci√≥n de p√©rdida, regulaci√≥n, etc. B√°sicamente explicar qu√© es lo que veremos en la siguiente secci√≥n. (1 punto)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa3f9b5",
   "metadata": {},
   "source": [
    "## Experimentos üß™\n",
    "\n",
    "**REQUIREMENTS: Reportar todos sus experimentos y c√≥digo en esta secci√≥n. Comparar los resultados obtenidos utilizando diferentes modelos. ¬°Es vital haber realizado varios experimentos para sacar una buena nota! (2.0 puntos)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1867bf5",
   "metadata": {},
   "source": [
    "## Conclusiones üí°\n",
    "\n",
    "**REQUIREMENTS: Discutir resultados, proponer trabajo futuro. (1 punto)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
